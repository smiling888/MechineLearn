四种不同的分离数据集的方法，用来分离训练数据集和评估数据集，并用其评估算法模型：
- 分离训练数据集和评估数据集。

    67%的数据作为训练集，将33%的数据作为评估数据集。
使用场景和特点：通常在具有大量数据、数据分布比较平衡，或者对问题的展示比较平均的情况下非常有效。这个方法非常快速，对某些执行比较慢的算法非常有效。

- K折交叉验证分离。
成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，再用这K个模型最终的验证集的分类准确率的平均数，作为此K折交叉验证下分类器的性能指标。

K次，求平均数

- 弃一交叉验证分离。
果原始数据有N个样本，那么弃一交叉验证就是N-1个交叉验证，即每个样本单独作为验证集，其余的N-1个样本作为训练集，所以弃一交叉验证会得到N个模型，用这N个模型最终的验证集的分类准确率的平均数作为此次弃一交叉验证分类器的性能指标
N次求平均值

- 重复随机评估、训练数据集分离。

另外一种K折交叉验证的用途是随机分离数据为训练数据集和评估数据集，但是重复这个过程多次，就如同交叉验证分离

## 黄金法则
通常会按照下面的原则来选择数据分离的方法：
- K折交叉验证是用来评估机器学习算法的黄金准则。通常会取K为3、5、10来分离数据。
- 分离训练数据集和评估数据集。因为执行效率比较高，通常会用于算法的执行效率比较低，或者具有大量数据的时候。
- 弃一交叉验证和重复随机分离评估数据集与训练数据集这两种方法，通常会用于平衡评估算法、模型训练的速度及数据集的大小。
- 还有一条黄金准则就是，当不知道如何选择分离数据集的方法时，请选择K折交叉验证来分离数据集；当不知道如何设定K值时，请将K值设为10。